			api = '807213406747273618873321229028917'			
			headers = {
			  'Accept': 'application/json'
			}

			# html = urllib.request.Request('https://api.scraperapi.com/?key=' + api + '&url=' + url + '&render=true', headers=headers)
			html = urllib.request.Request('https://api.scraperapi.com/?key=' + api + '&url=' + url, headers=headers)
			response = urllib.request.urlopen(html)
			soup = BeautifulSoup(response)

			page_title = soup.title.string

			# get open graph meta image
			og_img_meta = soup.find("meta",  property="og:image") 	
			if og_img_meta:
				ogimg = og_img_meta["content"]

			# if there was no open graph image
			if not og_img_meta:
				image_tags = soup.findAll('img')
				# loop through all img's found
				for img in image_tags:

					# get src from img
					imgurl = img.get('src')
					allimages.append(imgurl)
					# check a value is there and its not a data: src
					if (imgurl is not None) and ("data:" not in imgurl):

						# check if src starts without full path and append with domain appropriately 
						if not imgurl.startswith("http"):
							if imgurl.startswith("//"):
								imgurl = "https:" + imgurl
							else:
								imgurl = domain + imgurl

						# get the sizes		
						file = urllib.request.urlopen(imgurl)
						size = file.headers.get("content-length")
						if size: size = int(size)
						p = ImageFile.Parser()
						while 1:
							imgdata = file.read(1024)
							if not imgdata:
								break
							p.feed(imgdata)
							if p.image:
								if p.image.size[0] > 325 and p.image.size[1] > 325:
									sizes.append(p.image.size[0])
									data.append(imgurl)
								break
						file.close()